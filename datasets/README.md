
For a few datasets that detectron2 natively supports,
the datasets are assumed to exist in a directory called
"datasets/", under the directory where you launch the program.
They need to have the following directory structure:

## Expected dataset structure for COCO instance/keypoint detection:

```
coco/
  annotations/
    instances_{train,val}2017.json
    person_keypoints_{train,val}2017.json
  {train,val}2017/
    # image files that are mentioned in the corresponding json
```

You can use the 2014 version of the dataset as well.

Some of the builtin tests (`dev/run_*_tests.sh`) uses a tiny version of the COCO dataset,
which you can download with `./prepare_for_tests.sh`.

## Expected dataset structure for PanopticFPN:

```
coco/
  annotations/
    panoptic_{train,val}2017.json
  panoptic_{train,val}2017/
    # png annotations
  panoptic_stuff_{train,val}2017/  # generated by the script mentioned below
```

Install panopticapi by:
```
pip install git+https://github.com/cocodataset/panopticapi.git
```
Then, run `python prepare_panoptic_fpn.py`, to extract semantic annotations from panoptic annotations.

## Expected dataset structure for LVIS instance segmentation:
```
coco/
  {train,val,test}2017/
lvis/
  lvis_v0.5_{train,val}.json
  lvis_v0.5_image_info_test.json
```

Install lvis-api by:
```
pip install git+https://github.com/lvis-dataset/lvis-api.git
```

## Expected dataset structure for cityscapes:
```
cityscapes/
  gtFine/
    train/
      aachen/
        color.png, instanceIds.png, labelIds.png, polygons.json,
        labelTrainIds.png
      ...
    val/
    test/
  leftImg8bit/
    train/
    val/
    test/
```
Install cityscapes scripts by:
```
pip install git+https://github.com/mcordts/cityscapesScripts.git
```

Note:
labelTrainIds.png are created by `cityscapesscripts/preparation/createTrainIdLabelImgs.py`.
They are not needed for instance segmentation.

## Expected dataset structure for Pascal VOC:
```
VOC20{07,12}/
  Annotations/
  ImageSets/
  JPEGImages/
```

## Surface signs dataset
###Step by step:
- Copy the label definition file to surface_signs/Annotation and make sure it is name with the format "label_def_{annotation_name}" format.
- Copy the kitt format split file to surface_signs/Annotation as well.

- Run the following code to transform the kitt format data split into coco format.
    ```
    python prepare_surface_signs.py --split_file {split_name} --label_def_file label_def_{annotation_name}
    ```
    The resulted coco format annotation would be saved in 
    ```
    surface_signs/
    Annotations/
    surface_signs_{annotation_name}{traning/validation/test}.json
    ```
- Register surface signs
    Add the {annotation_name} to the List in 
    ```
    detectron2.data.datasets.builtin.register_all_ssigns() 
    ```
    to register the new data such that it can be used in training/inference.
    The registered dataset would be with name "ssigns_{train/val}_{annotation_name}"
